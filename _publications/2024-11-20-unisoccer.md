---
title: "Towards Universal Soccer Video Understanding"
collection: preprints
permalink: /publication/2024-11-20-unisoccer
date: 2024-11-20
paperurl: 'https://jyrao.github.io/UniSoccer/'

---
<div style="display: flex; align-items: center;"> <!-- 添加align-items: center; 来垂直居中所有子元素 -->
  <div style="flex: 1; width: 25%; text-align: center; margin-right: 5%;"> <!-- text-align: center; 用于水平居中图片 -->
    <img src="https://github.com/jyrao/jyrao.github.io/blob/master/images/research/unisoccer.png?raw=true" style="width: 100%; max-width: 100%; height: auto;" alt="描述">
  </div>
  <div style="flex: 3; width: 75%;">
    <p>
    <strong>Towards Universal Soccer Video Understanding</strong><br>
    <strong>Jiayuan Rao*</strong>, <a href="https://haoningwu3639.github.io/" target="_blank">Haoning Wu*</a>, <a href="https://scholar.google.nl/citations?user=0TvdOEcAAAAJ&hl=en" target="_blank">Hao Jiang</a>, <a href="https://mediabrain.sjtu.edu.cn/yazhang/" target="_blank">Ya Zhang</a>, <a href="https://cmic.sjtu.edu.cn/wangyanfeng/" target="_blank">Yanfeng Wang</a>, <a href="https://weidixie.github.io/" target="_blank">Weidi Xie</a><br>
    <em>In CVPR 2025</em> <span style="color: red;">(New)</span><br>
    [<a href="https://arxiv.org/abs/2412.01820" target="_blank">Paper</a>] / [<a href="https://jyrao.github.io/UniSoccer/" target="_blank">Webpage</a>] / [<a href="https://github.com/jyrao/UniSoccer" target="_blank">Code</a>] / [<a href="https://huggingface.co/datasets/Homie0609/SoccerReplay-1988" target="_blank">Dataset</a>] / [<a href="https://mp.weixin.qq.com/s/mEerB8hZjkb5ZU-ercBMLA" target="_blank">WeChat</a>]
    </p>
  </div>
</div>

As a globally celebrated sport, soccer has attracted widespread interest from fans over the world. This paper aims to develop a comprehensive multi-modal framework for soccer video understanding. Specifically, we make the following contributions in this paper: (i) we introduce SoccerReplay-1988, the largest multi-modal soccer dataset to date, featuring videos and detailed annotations from 1,988 complete matches, with an automated annotation pipeline; (ii) we present the first visual-language foundation model in the soccer domain, MatchVision, which leverages spatiotemporal information across soccer videos and excels in various downstream tasks; (iii) we conduct extensive experiments and ablation studies on action classification, commentary generation, and multi-view foul recognition, and demonstrate state-of-the-art performance on all of them, substantially outperforming existing models, which has demonstrated the superiority of our proposed data and model. We believe that this work will offer a standard paradigm for sports understanding research. The code and model will be publicly available for reproduction.